# ğŸ“š DocVision AI - Multimodal RAG Document Q&A System

**ğŸš€ An intelligent document Q&A system powered by Retrieval-Augmented Generation (RAG) and Multimodal AI**

## ğŸŒŸ Overview

**DocVision AI** is a production-ready AI application that enables users to upload documents (PDF, DOCX, TXT) and images, then ask natural language questions to receive accurate, context-aware answers with **relevant visual evidence**.

### ğŸ’¡ Problem It Solves

- âŒ Manual document reading is time-consuming
- âŒ Finding specific information in large PDFs is tedious  
- âŒ Images in documents often contain crucial information
- âŒ Traditional search doesn't understand context

### âœ… Solution

- âœ¨ AI-powered instant answers from your documents
- âœ¨ Smart image extraction and relevance matching
- âœ¨ Context-aware responses with source citations
- âœ¨ Zero setup - works in browser, completely free

---

## âœ¨ Features

### ğŸ¤– **Core Capabilities**

| Feature | Description |
|---------|-------------|
| **ğŸ“„ Multi-Format Support** | Process PDF, DOCX, TXT documents seamlessly |
| **ğŸ–¼ï¸ Image Intelligence** | Extract images from PDFs with AI-generated captions |
| **ğŸ¯ Smart Relevance** | Only shows images relevant to query (>25% threshold) |
| **ğŸ” Semantic Search** | FAISS vector database for lightning-fast retrieval |
| **ğŸ’¬ Natural Language Q&A** | Ask questions in plain English, get accurate answers |
| **ğŸ“Š Source Attribution** | Transparent citations with page numbers |
| **âš¡ Real-time Processing** | Progress tracking for all operations |
| **â˜ï¸ Cloud-Ready** | Deployed on Hugging Face Spaces |
| **ğŸ†“ Zero Cost** | Uses open-source models, no API keys needed |

### ğŸ¯ **Key Differentiators**

- **Multimodal Understanding**: Combines text and vision AI
- **Intelligent Image Filtering**: Only relevant images shown
- **Production-Grade**: Error handling, progress bars, clean UI
- **Fully Open Source**: No vendor lock-in

---

> **ğŸŒ Try it live:** [DocVision AI on Hugging Face Spaces](https://huggingface.co/spaces/Girinath11/DocVision-AI)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERFACE (Gradio)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DOCUMENT PROCESSING LAYER                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   PDF    â”‚  â”‚   DOCX   â”‚  â”‚   TXT    â”‚  â”‚  Images  â”‚   â”‚
â”‚  â”‚ PyMuPDF  â”‚  â”‚python-docâ”‚  â”‚  Parser  â”‚  â”‚ PIL/Pillowâ”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EMBEDDING & VECTORIZATION                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Sentence-Transformers (all-MiniLM-L6-v2)          â”‚     â”‚
â”‚  â”‚  384-dimensional dense vectors                     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  BLIP-Large (Vision Model)                         â”‚     â”‚
â”‚  â”‚  Image â†’ Text Caption Generation                   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                VECTOR DATABASE (FAISS)                       â”‚
â”‚  â€¢ IndexFlatL2 for L2 distance calculation                   â”‚
â”‚  â€¢ Fast approximate nearest neighbor search                  â”‚
â”‚  â€¢ O(log n) query time complexity                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  RETRIEVAL & MATCHING                        â”‚
â”‚  â€¢ Semantic search for text (top-3 chunks)                   â”‚
â”‚  â€¢ Cosine similarity for image-query matching                â”‚
â”‚  â€¢ Relevance threshold filtering (>25%)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ANSWER GENERATION (LLM)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  TinyLlama-1.1B-Chat                               â”‚     â”‚
â”‚  â”‚  Context-aware response generation                 â”‚     â”‚
â”‚  â”‚  Temperature: 0.7, Max tokens: 200                 â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OUTPUT                               â”‚
â”‚  â€¢ Answer with source citations & page numbers               â”‚
â”‚  â€¢ Relevant images with captions & relevance scores          â”‚
â”‚  â€¢ Metadata & statistics                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ RAG Pipeline Flow

1. **Document Ingestion** â†’ Extract text & images
2. **Chunking** â†’ Split text into 400-word segments
3. **Embedding** â†’ Convert to 384-dim vectors
4. **Indexing** â†’ Store in FAISS vector DB
5. **Query** â†’ User asks question
6. **Retrieval** â†’ Find top-3 relevant chunks
7. **Image Matching** â†’ Match query to image captions
8. **Generation** â†’ LLM creates contextual answer
9. **Response** â†’ Answer + sources + relevant images

---

## ğŸ› ï¸ Tech Stack

| Category | Technology | Purpose |
|----------|-----------|---------|
| **Frontend** | Gradio 4.x | Interactive web UI with real-time updates |
| **Embeddings** | Sentence-Transformers | Text to 384-dim vector conversion |
| **Vector DB** | FAISS (Facebook AI) | Ultra-fast similarity search |
| **LLM** | TinyLlama-1.1B-Chat | Lightweight answer generation |
| **Vision AI** | BLIP-Large | Image captioning & understanding |
| **Deep Learning** | PyTorch 2.x | Model inference backend |
| **PDF Processing** | PyMuPDF (fitz) | Extract text & images from PDFs |
| **Doc Processing** | python-docx, PyPDF2 | Parse Word & text documents |
| **Image Processing** | Pillow (PIL) | Image manipulation & validation |
| **Deployment** | Hugging Face Spaces | Serverless cloud hosting |

### ğŸ“Š Model Specifications

| Model | Size | Task | Speed |
|-------|------|------|-------|
| **all-MiniLM-L6-v2** | 80MB | Text Embeddings | ~1000 sent/sec |
| **TinyLlama-1.1B** | 2.2GB | Text Generation | 2-5 sec/query |
| **BLIP-Large** | 1.8GB | Image Captioning | 1-2 sec/image |

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- 8GB+ RAM
- GPU optional (works on CPU)

### ğŸ“¦ Installation

```bash
# Clone repository
git clone https://github.com/Giri530/DocVision_AI.git
cd docvision-ai

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### â–¶ï¸ Run Locally

```bash
python app.py
```

Access at `http://localhost:7860` ğŸ‰

---

## ğŸ“– Usage Guide

### Step 1: ğŸ“¤ Upload Documents

Click **"Upload Documents & Images"** and select:
- ğŸ“„ **Documents**: PDF, DOCX, TXT
- ğŸ–¼ï¸ **Images**: JPG, PNG, GIF

### Step 2: âš¡ Process

Click **"Process Documents"** and wait for:
- Text extraction from documents
- Image extraction from PDFs (min 150Ã—150px)
- AI caption generation for each image
- Vector embedding creation
- FAISS index building

**Status shows:** Text chunks, Images found, Sample captions

### Step 3: ğŸ’¬ Ask Questions

Type your question and click **"Get Answer"** to receive:
- ğŸ’¡ **AI-generated answer** (context-aware)
- ğŸ“š **Source citations** (with page numbers)
- ğŸ–¼ï¸ **Relevant images** (if relevance >25%)
- ğŸ¯ **Relevance scores** for each image

### ğŸ“ Example Questions

```
âœ… "What is the main topic of this document?"
âœ… "Summarize the key findings and conclusions"
âœ… "What statistics or numbers are mentioned?"
âœ… "Explain the workflow diagram shown"
âœ… "Describe the architecture in the images"
âœ… "What are the recommendations provided?"
```

---

## ğŸ¯ Use Cases

| Industry | Use Case |
|----------|----------|
| **Education** | Research paper analysis, study material Q&A |
| **Legal** | Contract review, case document analysis |
| **Healthcare** | Medical report interpretation, research papers |
| **Business** | Report analysis, meeting minutes extraction |
| **Engineering** | Technical documentation, diagram analysis |
| **Research** | Literature review, data extraction |

---

## ğŸ“Š Performance Benchmarks

| Metric | Value | Description |
|--------|-------|-------------|
| **Embedding Speed** | ~1000 sent/sec | Text vectorization |
| **Search Latency** | <100ms | FAISS similarity search |
| **Caption Generation** | 1-2 sec/image | BLIP-Large inference |
| **Answer Generation** | 2-5 seconds | LLM response time |
| **Total Query Time** | 5-10 seconds | End-to-end latency |
| **Max Document Size** | 50MB | Per PDF file |
| **Concurrent Users** | 10+ | HF Spaces free tier |

---

## ğŸ“ Project Structure

```
docvision-ai/
â”œâ”€â”€ app.py                  # Main application
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .python-version        # Python 3.11
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ LICENSE                # MIT License
â”œâ”€â”€ .gitignore             # Git ignore rules
```

---

## ğŸ§ª Technical Deep Dive

### Text Processing Pipeline

```python
# 1. Extract text
text = extract_from_pdf(file)

# 2. Chunk text (400 words)
chunks = chunk_text(text, size=400)

# 3. Generate embeddings
embeddings = model.encode(chunks)  # 384-dim vectors

# 4. Index with FAISS
index = faiss.IndexFlatL2(384)
index.add(embeddings)
```

### Image Processing Pipeline

```python
# 1. Extract images from PDF
images = pdf.get_images()

# 2. Filter by size
valid_images = [img for img in images if img.size >= (150,150)]

# 3. Generate captions
caption = blip_model.generate(image)

# 4. Match to query
similarity = cosine_sim(query_emb, caption_emb)
if similarity > 0.25:
    show_image(image, caption, similarity)
```

### RAG Implementation

```python
# Retrieval
relevant_docs = search(query, k=3)

# Augmentation
context = "\n\n".join([doc.text for doc in relevant_docs])

# Generation
answer = llm.generate(
    prompt=f"Context: {context}\nQuestion: {query}\nAnswer:",
    max_tokens=200
)
```

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** changes (`git commit -m 'Add AmazingFeature'`)
4. **Push** to branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

### ğŸ’¡ Ideas for Contribution

- [ ] Add support for PPTX, XLSX files
- [ ] Implement chat history/memory
- [ ] Add multilingual support
- [ ] Create REST API endpoints
- [ ] Add export to PDF functionality
- [ ] Implement OCR for scanned documents
- [ ] Add user authentication
- [ ] Create mobile app version

---

## ğŸ› Known Issues & Limitations

| Issue | Impact | Workaround |
|-------|--------|------------|
| Large PDFs (>50MB) | Slow processing | Split into smaller files |
| Scanned PDFs | No text extraction | Use OCR preprocessing |
| GPU memory | Limited on free tier | Uses CPU automatically |
| Caption quality | Varies by image | Using BLIP-Large helps |
| Relevance threshold | May miss some images | Adjust threshold in code |

---

## ğŸ“ˆ Roadmap

### âœ… Version 1.0 (Current)
- [x] Multi-format document support
- [x] Image extraction & captioning
- [x] Semantic search with FAISS
- [x] RAG-based Q&A
- [x] HF Spaces deployment

### ğŸš§ Version 1.1 (In Progress)
- [ ] OCR for scanned documents
- [ ] Chat history
- [ ] Better error handling

### ğŸ”® Version 2.0 (Future)
- [ ] Multi-language support
- [ ] API endpoints
- [ ] User authentication
- [ ] Advanced analytics

---

## ğŸ“ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

```
MIT License - Copyright (c) 2026 Girinath
```

---

## ğŸ™ Acknowledgments

- **Hugging Face** - For amazing model hub and Spaces
- **Sentence-Transformers** - For embedding models
- **Facebook AI** - For FAISS library
- **TinyLlama Team** - For lightweight LLM
- **Salesforce Research** - For BLIP models
- **Gradio Team** - For the awesome UI framework
- **PyTorch Community** - For deep learning tools

---

## ğŸ“§ Contact & Support

**Girinath**  
- ğŸŒ **Live Demo**: [DocVision AI](https://huggingface.co/spaces/Girinath11/DocVision-AI)
- ğŸ’» **GitHub**: [@Girinath11](https://github.com/Giri530)
- ğŸ¤— **Hugging Face**: [@Girinath11](https://huggingface.co/Girinath11)
- â­ **Star the repo** if you find it useful!

---

**Made with â¤ï¸ by Girinath | Powered by AI**
